# ServiceMonitor for Prometheus Operator
# This requires Prometheus Operator to be installed
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: llm-config-manager
  namespace: llm-config
  labels:
    app: llm-config-manager
    component: monitoring
    prometheus: kube-prometheus
spec:
  selector:
    matchLabels:
      app: llm-config-manager
      component: api

  namespaceSelector:
    matchNames:
      - llm-config

  endpoints:
    - port: metrics
      interval: 30s
      scrapeTimeout: 10s
      path: /metrics
      scheme: http

      # Relabeling
      relabelings:
        - sourceLabels: [__meta_kubernetes_pod_name]
          targetLabel: pod
        - sourceLabels: [__meta_kubernetes_pod_node_name]
          targetLabel: node
        - sourceLabels: [__meta_kubernetes_namespace]
          targetLabel: namespace

      # Metric relabeling (optional)
      metricRelabelings:
        - sourceLabels: [__name__]
          regex: 'go_.*'
          action: drop  # Drop Go runtime metrics if not needed

---
# PrometheusRule for alerts
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: llm-config-manager-alerts
  namespace: llm-config
  labels:
    app: llm-config-manager
    component: monitoring
    prometheus: kube-prometheus
spec:
  groups:
    - name: llm_config_critical
      interval: 30s
      rules:
        - alert: LLMConfigManagerDown
          expr: up{job="llm-config-manager"} == 0
          for: 1m
          labels:
            severity: critical
            component: api
          annotations:
            summary: "LLM Config Manager is down"
            description: "LLM Config Manager has been down for more than 1 minute"

        - alert: LLMConfigHighErrorRate
          expr: |
            sum(rate(config_errors_total[5m])) /
            sum(rate(config_operations_total[5m])) > 0.10
          for: 5m
          labels:
            severity: critical
            component: api
          annotations:
            summary: "High error rate detected"
            description: "Error rate is {{ $value | humanizePercentage }}"

        - alert: LLMConfigHighLatency
          expr: |
            histogram_quantile(0.95,
              rate(http_request_duration_seconds_bucket[5m])
            ) > 0.1
          for: 5m
          labels:
            severity: warning
            component: api
          annotations:
            summary: "High latency detected"
            description: "P95 latency is {{ $value | humanizeDuration }}"

        - alert: LLMConfigPodCrashLooping
          expr: |
            rate(kube_pod_container_status_restarts_total{
              namespace="llm-config",
              pod=~"llm-config-manager-.*"
            }[15m]) > 0
          for: 5m
          labels:
            severity: warning
            component: api
          annotations:
            summary: "Pod is crash looping"
            description: "Pod {{ $labels.pod }} is crash looping"

        - alert: LLMConfigLowCacheHitRate
          expr: |
            sum(rate(cache_hits_total[5m])) /
            (sum(rate(cache_hits_total[5m])) + sum(rate(cache_misses_total[5m]))) < 0.7
          for: 10m
          labels:
            severity: warning
            component: cache
          annotations:
            summary: "Low cache hit rate"
            description: "Cache hit rate is {{ $value | humanizePercentage }}"

        - alert: LLMConfigHighMemoryUsage
          expr: |
            container_memory_usage_bytes{
              namespace="llm-config",
              pod=~"llm-config-manager-.*"
            } / container_spec_memory_limit_bytes{
              namespace="llm-config",
              pod=~"llm-config-manager-.*"
            } > 0.9
          for: 5m
          labels:
            severity: warning
            component: resources
          annotations:
            summary: "High memory usage"
            description: "Pod {{ $labels.pod }} memory usage is {{ $value | humanizePercentage }}"
